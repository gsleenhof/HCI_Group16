# HCI_Group16

Project Description: Our project allows users to complete a short survey by moving their body according to their answers to our questions, and tracking their position using the Kinect camera. After completing the survey, the user will be shown different events going on around Yale that they would be able to attend (based on their answers)

Problem Space: Students do not know about Yale events that occur outside of their social circles and, thus, miss out on opportunities to support fellow students.

Tasks: 
- Filter by logistics that go into attending events (such as time, ticket information, and location).
- Save info or link about specific event going on that they may be interested in.

Deployment Environment Constraints: We have developed our code to make the interaction as simple and smooth as possible for potential users. Only one user can be "tracked" at a time by our code, so if the user is in a busy hallway or there is lots of traffic behind the user, the tracking may be a little bumpy. Regarding the distance of the user from the display and the physical contrains of the tracking, we have tested our code so that any user picked up by the display will be able to use the display. That being said, being closer to the screen is better, and staying in front of the display the entire time it is being used is suggested.

There are no additional dependecies to run this project outside the scope of the class. That is, you need access to display 2 at Yale University and to be connected to the Yale VPN, but nothing specifically in the code is required.

Collaboration Record:

Gabriel Sleenhof - ggs25: 
